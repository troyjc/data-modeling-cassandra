{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/troy/Documents/data-engineering/Projects/data-modeling-cassandra\n"
     ]
    }
   ],
   "source": [
    "# Checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get the current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # Join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows(file):\n",
    "    \"\"\"Process the rows of the specified csv file.\n",
    "    \n",
    "    Args:\n",
    "        file (string): csv file to process.\n",
    "    \n",
    "    Yields:\n",
    "        list: The next row of the file.\n",
    "    \"\"\"\n",
    "    # Read the csv file \n",
    "    with open(file, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # Create a csv reader object\n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)  # Skip the header\n",
    "\n",
    "        for line in csvreader:\n",
    "            yield line\n",
    "            \n",
    "# Create a smaller event data csv file with fewer columns called event_datafile_full.csv\n",
    "# that will be used to insert data into the Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for file in file_path_list:\n",
    "        for row in rows(file):\n",
    "            if (row[0] == ''):\n",
    "                continue\n",
    "            writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], \\\n",
    "                             row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in the csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of the project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a connection to a Cassandra instance on the local machine (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KEYSPACE if it doesn't exist\n",
    "try:\n",
    "    session.execute(\"\"\"CREATE  KEYSPACE IF NOT EXISTS udacity \n",
    "                       WITH REPLICATION =\n",
    "                       { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n",
    "                    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables to run the three queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1:  Return the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4\n",
    "\n",
    "#### Use the sessionId as the partition key and the itemInSession as the clustering column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"CREATE TABLE IF NOT EXISTS sessions (\n",
    "                       session_id bigint, item_in_session int, artist text, song_title text, length decimal,\n",
    "                       PRIMARY KEY (session_id, item_in_session))\n",
    "                    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)  # Skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO sessions (session_id, item_in_session, artist, song_title, length)\"\n",
    "        query = query + \" VALUES(%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], Decimal(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist                       song_title    length\n",
      "0  Faithless  Music Matters (Mark Knight Dub)  495.3073\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(\"\"\"SELECT artist, song_title, length\n",
    "                              FROM sessions\n",
    "                              WHERE session_id = 338 AND item_in_session = 4\"\"\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df = pd.DataFrame(list(rows), columns=['artist', 'song_title', 'length'])\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Return only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "#### Use a composite partition key consisting of the userId and the sessionId and the itemInSession as the clustering column to sort the results\n",
    "\n",
    "#### Combine the first and last name into a single column to simplify the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"CREATE TABLE IF NOT EXISTS user_sessions (\n",
    "                       user_id bigint, session_id bigint, item_in_session int,\n",
    "                       artist text, song text, user text,\n",
    "                       PRIMARY KEY ((user_id, session_id), item_in_session))\n",
    "                    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_sessions (user_id, session_id, item_in_session, artist, song, user)\"\n",
    "        query = query + \" VALUES(%s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], \\\n",
    "                                line[9], ' '.join([line[1], line[4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Artist                                               Song         User\n",
      "0   Down To The Bone                                 Keep On Keepin' On  Sylvie Cruz\n",
      "1       Three Drives                                        Greece 2000  Sylvie Cruz\n",
      "2  Sebastien Tellier                                          Kilometer  Sylvie Cruz\n",
      "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...  Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(\"\"\"SELECT artist, song, user\n",
    "                              FROM user_sessions\n",
    "                              WHERE user_id = 10 AND session_id = 182\"\"\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    " \n",
    "df = pd.DataFrame(list(rows), columns=['Artist', 'Song', 'User'])\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Return every user name (first and last) in the music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "#### Use the song title as the partition key and the userId as the clustering column\n",
    "\n",
    "#### Combine the first and last name into a single column to simplify the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"CREATE TABLE IF NOT EXISTS song_plays (\n",
    "                       song text, user_id bigint, user text,\n",
    "                       PRIMARY KEY (song, user_id))\n",
    "                    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_plays (song, user_id, user)\"\n",
    "        query = query + \" VALUES(%s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), ' '.join([line[1], line[4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               User\n",
      "0  Jacqueline Lynch\n",
      "1      Tegan Levine\n",
      "2      Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(\"\"\"SELECT user\n",
    "                              FROM song_plays\n",
    "                              WHERE song = 'All Hands Against His Own'\"\"\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame(list(rows), columns=['User'])\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x1180c2390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"DROP TABLE IF EXISTS sessions\")\n",
    "session.execute(\"DROP TABLE IF EXISTS user_sessions\")\n",
    "session.execute(\"DROP TABLE IF EXISTS song_plays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
